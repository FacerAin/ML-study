{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "char_set:['<pad>', ' ', 'g', 'm', 'd', 'c', 'w', 't', 'i', 's', 'a', 'o', 'n', 'u', 'r', 'e', 'p', 'l', 'h']\nchar_set length:19\n"
    }
   ],
   "source": [
    "data = ['hello world',\n",
    "        'midnight',\n",
    "        'calculation',\n",
    "        'path',\n",
    "        'short circuit']\n",
    "\n",
    "# Make dictionary\n",
    "char_set = ['<pad>'] + list(set(char for seq in data for char in seq)) # Get all characters and include pad token\n",
    "char2idx = {char: idx for idx, char in enumerate(char_set)} # Constuct character to index dictionary\n",
    "print('char_set:', char_set)\n",
    "print('char_set length:', len(char_set))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([18, 15, 17, 17, 11,  1,  6, 11, 14, 17,  4])\ntensor([ 3,  8,  4, 12,  8,  2, 18,  7])\ntensor([ 5, 10, 17,  5, 13, 17, 10,  7,  8, 11, 12])\ntensor([16, 10,  7, 18])\ntensor([ 9, 18, 11, 14,  7,  1,  5,  8, 14,  5, 13,  8,  7])\n"
    }
   ],
   "source": [
    "# Convert character to index and make list of tensors\n",
    "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in X:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "lengths:[11, 8, 11, 4, 13]\n"
    }
   ],
   "source": [
    "lengths = [len(seq) for seq in X]\n",
    "print('lengths:', lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[18, 15, 17, 17, 11,  1,  6, 11, 14, 17,  4,  0,  0],\n        [ 3,  8,  4, 12,  8,  2, 18,  7,  0,  0,  0,  0,  0],\n        [ 5, 10, 17,  5, 13, 17, 10,  7,  8, 11, 12,  0,  0],\n        [16, 10,  7, 18,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n        [ 9, 18, 11, 14,  7,  1,  5,  8, 14,  5, 13,  8,  7]])\ntorch.Size([5, 13])\n"
    }
   ],
   "source": [
    "padded_sequence = pad_sequence(X, batch_first=True) # X is now padded sequence\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([ 9, 18, 11, 14,  7,  1,  5,  8, 14,  5, 13,  8,  7])\ntensor([18, 15, 17, 17, 11,  1,  6, 11, 14, 17,  4])\ntensor([ 5, 10, 17,  5, 13, 17, 10,  7,  8, 11, 12])\ntensor([ 3,  8,  4, 12,  8,  2, 18,  7])\ntensor([16, 10,  7, 18])\n"
    }
   ],
   "source": [
    "# Sort by descending lengths\n",
    "sorted_idx = sorted(range(len(lengths)), key=lengths.__getitem__, reverse=True)\n",
    "sorted_X = [X[idx] for idx in sorted_idx]\n",
    "\n",
    "# Check converted result\n",
    "for sequence in sorted_X:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PackedSequence(data=tensor([ 9, 18,  5,  3, 16, 18, 15, 10,  8, 10, 11, 17, 17,  4,  7, 14, 17,  5,\n        12, 18,  7, 11, 13,  8,  1,  1, 17,  2,  5,  6, 10, 18,  8, 11,  7,  7,\n        14, 14,  8,  5, 17, 11, 13,  4, 12,  8,  7]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
    }
   ],
   "source": [
    "packed_sequence = pack_sequence(sorted_X)\n",
    "print(packed_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 13, 19])\n"
    }
   ],
   "source": [
    "# one-hot embedding using PaddedSequence\n",
    "eye = torch.eye(len(char_set)) # Identity matrix of shape (len(char_set), len(char_set))\n",
    "embedded_tensor = eye[padded_sequence]\n",
    "print(embedded_tensor.shape) # shape: (Batch_size, max_sequence_length, number_of_input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([47, 19])\n"
    }
   ],
   "source": [
    "# one-hot embedding using PackedSequence\n",
    "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
    "print(embedded_packed_seq.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 13, 30])\ntorch.Size([1, 5, 30])\n"
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_tensor)\n",
    "print(rnn_output.shape) # shape: (batch_size, max_seq_length, hidden_size)\n",
    "print(hidden.shape)     # shape: (num_layers * num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([47, 30])\ntorch.Size([1, 5, 30])\n"
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_packed_seq)\n",
    "print(rnn_output.data.shape)\n",
    "print(hidden.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 13, 19])\ntensor([13, 11, 11,  8,  4])\n"
    }
   ],
   "source": [
    "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
    "print(unpacked_sequence.shape)\n",
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([5, 13, 19])\n"
    }
   ],
   "source": [
    "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
    "print(embedded_padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([47, 19])\ntensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
    }
   ],
   "source": [
    "sorted_lengths = sorted(lengths, reverse=True)\n",
    "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
    "print(new_packed_sequence.data.shape)\n",
    "print(new_packed_sequence.batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}